{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import datetime\n",
    "import re\n",
    "# import sys\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import hamming_loss, make_scorer, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_to_words(raw_tweet):\n",
    "    tweet = raw_tweet.lower()\n",
    "    \n",
    "    tweet = re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', '', tweet)\n",
    "    \n",
    "    tweet = re.sub(r'@[\\S]+', '', tweet)\n",
    "    \n",
    "    tweet = re.sub(r'#(\\S+)', r' \\1 ', tweet)\n",
    "    \n",
    "    tweet = tweet.strip(' \"\\'')\n",
    "    \n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    \n",
    "    tweet = tweet.strip('\\'\"?!,.():;')\n",
    "    \n",
    "    word_tokens = tweet.split()\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_reviews(df_):\n",
    "    num = len(df_)\n",
    "    train_reviews = []\n",
    "    for i in range(num):\n",
    "        train_reviews.append(tweet_to_words(df_['Text'][i]))\n",
    "    return train_reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data_features(train_reviews):\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                                 tokenizer = None,    \\\n",
    "                                 preprocessor = None, \\\n",
    "                                 stop_words = None,   \\\n",
    "                                 max_features = 5000) \n",
    "    train_data_features = vectorizer.fit_transform(train_reviews)\n",
    "\n",
    "    train_data_features = train_data_features.toarray()\n",
    "\n",
    "    return train_data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NBModel(X_train, X_test, y_train, y_test):\n",
    "    model_M = MultinomialNB()\n",
    "#     model_G = GaussianNB()\n",
    "    model_M.fit(X_train,y_train)\n",
    "#     model_G.fit(X_train,y_train)\n",
    "    y_train_M = model_M.predict(X_train)\n",
    "    y_test_M = model_M.predict(X_test)\n",
    "    precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_M,average='macro')\n",
    "    precision_te,recall_te,fscore_te,support=score(y_test,y_test_M,average='macro')\n",
    "    return accuracy_score(y_train,y_train_M),precision_tr,recall_tr,fscore_tr,accuracy_score(y_test,y_test_M),precision_te,recall_te,fscore_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def SVMmodel(X_train, X_test, y_train, y_test):\n",
    "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_train_svm = clf.predict(X_train)\n",
    "    y_test_svm = clf.predict(X_test)  \n",
    "    precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_svm,average='macro')\n",
    "    precision_te,recall_te,fscore_te,support=score(y_test,y_test_svm,average='macro')\n",
    "    return accuracy_score(y_train,y_train_svm),precision_tr,recall_tr,fscore_tr,accuracy_score(y_test,y_test_svm),precision_te,recall_te,fscore_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Tweets_sample.csv', sep = ',')\n",
    "train_reviews = get_train_reviews(df)\n",
    "train_data_features = get_train_data_features(train_reviews)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBscores_train = []\n",
    "SVMscores_train = []\n",
    "NBscores_test = []\n",
    "SVMscores_test = []\n",
    "random = []\n",
    "for i in range(5):\n",
    "    random.append(i)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=i)\n",
    "    NB_train, NB_test = NBModel(X_train, X_test, y_train, y_test)\n",
    "    SVM_train, SVM_test = SVMmodel(X_train, X_test, y_train, y_test)\n",
    "    print(\"i:\")\n",
    "    print(NB_train, NB_test,SVM_train, SVM_test)\n",
    "    NBscores_train.append(NB_train)\n",
    "    NBscores_test.append(NB_test)\n",
    "    SVMscores_train.append(SVM_train)\n",
    "    SVMscores_test.append(SVM_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision,recall,fscore,support=score(y_train,y_train_M,average='macro')\n",
    "print ('Precision : {}'.format(precision))\n",
    "print ('Recall    : {}'.format(recall))\n",
    "print ('F-score   : {}'.format(fscore))\n",
    "print ('Support   : {}'.format(support))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_Test[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837897853441895 0.8801195013767753 0.8672193303250147 0.8728668742526455 0.7435173617960127 0.7675489067894131 0.7468670306688354 0.7407996119313777\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9205526770293609 0.941387285277969 0.8931422287520685 0.9101172425116643 0.7209436133486766 0.941387285277969 0.8931422287520685 0.9101172425116643\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8860103626943006 0.8829681488520653 0.8673493044822257 0.8740915020374131 0.723735933650589 0.7485615650172612 0.7305382243258749 0.7194355048586629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train= scaler.fit_transform(X_train)\n",
    "# X_test= scaler.fit_transform(X_test)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.924006908462867 0.9447904215392693 0.895917228901045 0.9134245838107153 0.7077100115074798 0.7727462358250844 0.6124987023181929 0.597315264824788\n"
     ]
    }
   ],
   "source": [
    "accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_test_lr = clf.predict(X_test)\n",
    "y_train_lr = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7025316455696202"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_test_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tr = accuracy_score(y_train, y_train_lr)\n",
    "accuracy_te = accuracy_score(y_test, y_test_lr)\n",
    "\n",
    "precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_lr,average='macro')\n",
    "precision_te,recall_te,fscore_te,support=score(y_test,y_test_lr,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997285961016531 0.9969872449665687 0.9971343190677899 0.9970607054030133 0.7025316455696202 0.6814780457637601 0.6836209091025446 0.6824561124510766\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837897853441895 0.8801195013767753 0.8672193303250147 0.8728668742526455 0.7435173617960127 0.7675489067894131 0.7468670306688354 0.7407996119313777\n",
      "0.9205526770293609 0.941387285277969 0.8931422287520685 0.9101172425116643 0.7209436133486766 0.7753358527856418 0.6190669028572419 0.6106593059922338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985196150999259 0.9984066901454591 0.9984066901454591 0.9984066901454591 0.7192174913693901 0.6977661809574855 0.7061535152116258 0.7007275883727002\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train= scaler.fit_transform(X_train)\n",
    "# X_test= scaler.fit_transform(X_test)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_test_lr = clf.predict(X_test)\n",
    "y_train_lr = clf.predict(X_train)\n",
    "accuracy_score(y_test, y_test_lr)\n",
    "accuracy_tr = accuracy_score(y_train, y_train_lr)\n",
    "accuracy_te = accuracy_score(y_test, y_test_lr)\n",
    "\n",
    "precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_lr,average='macro')\n",
    "precision_te,recall_te,fscore_te,support=score(y_test,y_test_lr,average='macro')\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8882309400444115 0.8845945401791624 0.8694536807662248 0.8760618146094998 0.7266086491828901 0.7479861910241657 0.732423688571798 0.7228751521572517\n",
      "0.921539600296077 0.9434543267109361 0.8914140183077881 0.9098953017206424 0.6990794016110472 0.775394985325789 0.6082739732203237 0.587810822882822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.997779422649889 0.9973583831859812 0.9978130009140647 0.9975849937921688 0.7261219792865362 0.7087750873212861 0.7095163090032008 0.7091360656821285\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=99)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train= scaler.fit_transform(X_train)\n",
    "# X_test= scaler.fit_transform(X_test)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_test_lr = clf.predict(X_test)\n",
    "y_train_lr = clf.predict(X_train)\n",
    "accuracy_score(y_test, y_test_lr)\n",
    "accuracy_tr = accuracy_score(y_train, y_train_lr)\n",
    "accuracy_te = accuracy_score(y_test, y_test_lr)\n",
    "\n",
    "precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_lr,average='macro')\n",
    "precision_te,recall_te,fscore_te,support=score(y_test,y_test_lr,average='macro')\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8837897853441895 0.8801195013767753 0.8672193303250147 0.8728668742526455 0.7435173617960127 0.7675489067894131 0.7468670306688354 0.7407996119313777\n",
      "0.9205526770293609 0.941387285277969 0.8931422287520685 0.9101172425116643 0.7209436133486766 0.7753358527856418 0.6190669028572419 0.6106593059922338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9985196150999259 0.9984066901454591 0.9984066901454591 0.9984066901454591 0.7192174913693901 0.6977661809574855 0.7061535152116258 0.7007275883727002\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state=42)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train= scaler.fit_transform(X_train)\n",
    "# X_test= scaler.fit_transform(X_test)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)\n",
    "accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)\n",
    "scaler = StandardScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test= scaler.fit_transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_test_lr = clf.predict(X_test)\n",
    "y_train_lr = clf.predict(X_train)\n",
    "accuracy_score(y_test, y_test_lr)\n",
    "accuracy_tr = accuracy_score(y_train, y_train_lr)\n",
    "accuracy_te = accuracy_score(y_test, y_test_lr)\n",
    "\n",
    "precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_lr,average='macro')\n",
    "precision_te,recall_te,fscore_te,support=score(y_test,y_test_lr,average='macro')\n",
    "print(accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rd:  21\n",
      "nb 0.8877374784110535 0.8840551882743577 0.8720830975287681 0.8773788368671713 0.7349542992496761 0.7600690448791715 0.7383258834256232 0.732246879334258\n",
      "svm 0.922773254379472 0.9439136528488727 0.8956718072061876 0.9126792711278452 0.715765247410817 0.7726715161888461 0.6104773462783172 0.5982431807674526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9975326918332099 0.9973452336037225 0.9973452336037225 0.9973452336037225 0.7065592635212888 0.6854885769336636 0.6947179842810911 0.6883600703737092\n",
      "rd:  34\n",
      "nb 0.8842832469775475 0.879918894071535 0.8670977813933785 0.8727537182841894 0.7217229647489771 0.7456846950517837 0.726122880699596 0.7185589809178754\n",
      "svm 0.923513446829509 0.9452716509271779 0.8950735215084924 0.9128624057835122 0.7025316455696202 0.775684135494468 0.6014690512549602 0.5806428879788115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.998026153466568 0.9977195308628843 0.9980114049489237 0.9978651623250927 0.7232451093210587 0.7035401932130028 0.708125337747759 0.7054667998442739\n",
      "rd:  15\n",
      "nb 0.8860103626943006 0.8830495928941524 0.867936816179605 0.8744676988392885 0.7188130435340883 0.7462600690448792 0.7265657152540732 0.7140779023968319\n",
      "svm 0.926720947446336 0.9455918866177422 0.9006417846824232 0.9170483276094241 0.7065592635212888 0.757148610551752 0.6086280228460323 0.5943801344286781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9985196150999259 0.9982561702015753 0.998545919575617 0.9984007401394102 0.7077100115074798 0.6859714476130345 0.6894969726862674 0.6874985842111224\n",
      "rd:  55\n",
      "nb 0.8837897853441895 0.8806984478935698 0.8656300576393424 0.8721274077807393 0.7301221817547725 0.7520138089758343 0.7316026826173645 0.7288106698756518\n",
      "svm 0.9222797927461139 0.9435118950808037 0.8943057882266832 0.9117158632354634 0.716915995397008 0.7636532802492644 0.6221921379863617 0.6144444023612291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.998026153466568 0.9977260007619848 0.9980136195424818 0.997869506343646 0.716915995397008 0.696167974620137 0.7019683685748668 0.6984579708182403\n",
      "rd:  63\n",
      "nb 0.8832963237108314 0.8779048639137005 0.8658801774560922 0.871244402573703 0.7291463502384097 0.7520138089758343 0.7363702303237851 0.724731041480307\n",
      "svm 0.9252405625462621 0.9460208112534927 0.8967834099188114 0.9145427774615038 0.7071346375143843 0.7986686566277584 0.6136839933468714 0.5948363552758311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.997779422649889 0.9973643521491948 0.9978143377538631 0.9975886496973765 0.7163406214039125 0.6971953222335485 0.6968283173434968 0.6970094305962362\n",
      "rd:  80\n",
      "nb 0.8823094004441154 0.8783652749571236 0.8639146250720493 0.8701987657582684 0.7374083201314323 0.762945914844649 0.7476110482172638 0.7315687613843351\n",
      "svm 0.922773254379472 0.9448541106000337 0.8938380906526546 0.9118627353372566 0.7059838895281934 0.7742984508763318 0.6089281648451731 0.5918731041049445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.998272884283247 0.9979111651109513 0.9983515014467869 0.9981306440682656 0.7278481012658228 0.7074071430101156 0.7067238729508196 0.7070586453572797\n",
      "rd:  39\n",
      "nb 0.8847767086109055 0.8820452837639935 0.8663507383203377 0.8730882024290211 0.7390469508172107 0.760644418872267 0.7412911843406645 0.737145982130714\n",
      "svm 0.923513446829509 0.943479335487174 0.8963655967705881 0.913268067340588 0.713463751438435 0.7615101904443702 0.6176542589514643 0.6078349282296651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9975326918332099 0.997192458273233 0.9974803750115054 0.9973361127674141 0.7226697353279632 0.7021748371136893 0.7076764058712959 0.7044071672041834\n",
      "rd:  26\n",
      "nb 0.8902047865778435 0.8872071177470553 0.8719398062592909 0.8785815656120424 0.742361353331008 0.7652474108170311 0.750842265315447 0.7372205072555134\n",
      "svm 0.923019985196151 0.945423183898077 0.8935272942304247 0.9118810385379346 0.7094361334867664 0.78720762688154 0.6163417989253085 0.6006860798136483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.9975326918332099 0.9973227350721838 0.9973227350721838 0.9973227350721838 0.716915995397008 0.6976669377733015 0.6993527200914607 0.6984579708182403\n"
     ]
    }
   ],
   "source": [
    "from random import randrange \n",
    "for i in range(8):\n",
    "    rd = randrange(100)\n",
    "    print(\"rd: \", rd)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train_data_features, df['Sentiment'].values, test_size=0.3, random_state = rd)\n",
    "    accuracy_tr,precision_tr,recall_tr,fscore_tr,precision_te,recall_te,fscore_te,accuracy_te = NBModel(X_train, X_test, y_train, y_test)\n",
    "    print(\"nb\",accuracy_tr,precision_tr,recall_tr,fscore_tr,accuracy_te,precision_te,recall_te,fscore_te,)\n",
    "    accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te= SVMmodel(X_train, X_test, y_train, y_test)\n",
    "    print(\"svm\",accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)\n",
    "    scaler = StandardScaler()\n",
    "    X_train= scaler.fit_transform(X_train)\n",
    "    X_test= scaler.fit_transform(X_test)\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "    y_test_lr = clf.predict(X_test)\n",
    "    y_train_lr = clf.predict(X_train)\n",
    "    accuracy_score(y_test, y_test_lr)\n",
    "    accuracy_tr = accuracy_score(y_train, y_train_lr)\n",
    "    accuracy_te = accuracy_score(y_test, y_test_lr)\n",
    "\n",
    "    precision_tr,recall_tr,fscore_tr,support=score(y_train,y_train_lr,average='macro')\n",
    "    precision_te,recall_te,fscore_te,support=score(y_test,y_test_lr,average='macro')\n",
    "    print(\"lr\",accuracy_tr,precision_tr,recall_tr,fscore_tr, accuracy_te, precision_te,recall_te,fscore_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
